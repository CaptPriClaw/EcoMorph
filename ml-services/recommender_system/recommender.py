# ml-services/recommender_system/recommender.py

import os
import joblib
from sklearn.metrics.pairwise import cosine_similarity

# Import the shared text preprocessing pipeline
from ..ai_registry.base_pipeline import preprocess_text


class Recommender:
    """
    A content-based recommender system using TF-IDF and Cosine Similarity.
    """

    def __init__(self):
        """
        Loads the pre-trained vectorizer and the product-vector matrix.

        Note: The .pkl files are generated by a separate training script
        that fits the vectorizer on a corpus of product descriptions.
        """
        current_dir = os.path.dirname(__file__)
        vectorizer_path = os.path.join(current_dir, 'vectorizer.pkl')
        model_path = os.path.join(current_dir, 'model.pkl')

        try:
            self.vectorizer = joblib.load(vectorizer_path)
            # The 'model.pkl' for this recommender contains both the TF-IDF matrix
            # and the list of product names.
            model_data = joblib.load(model_path)
            self.tfidf_matrix = model_data['matrix']
            self.product_names = model_data['names']
        except FileNotFoundError as e:
            print(f"Error loading model files: {e}")
            print("Please ensure 'vectorizer.pkl' and 'model.pkl' exist.")
            # In a real app, you might want to handle this more gracefully.
            self.vectorizer = None
            self.tfidf_matrix = None
            self.product_names = []

    def recommend(self, waste_description: str, top_n: int = 3) -> list:
        """
        Recommends the top N products based on a waste item description.

        Args:
            waste_description (str): Text describing the waste item (e.g., "old newspapers").
            top_n (int): The number of recommendations to return.

        Returns:
            A list of the top N recommended product names.
        """
        if not all([self.vectorizer, self.tfidf_matrix is not None, self.product_names]):
            return ["Recommender system is not available."]

        # 1. Preprocess the input text using the shared pipeline
        clean_description = preprocess_text(waste_description)

        # 2. Transform the text into a TF-IDF vector using the loaded vectorizer
        query_vector = self.vectorizer.transform([clean_description])

        # 3. Compute cosine similarity between the query vector and all product vectors
        cosine_similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()

        # 4. Get the indices of the top N most similar products
        # We use argsort to get indices, then [-n-1:-1] and reverse to get top N descending
        top_indices = cosine_similarities.argsort()[-top_n:][::-1]

        # 5. Map indices to product names and return
        recommendations = [self.product_names[i] for i in top_indices]

        return recommendations


# Example usage:
if __name__ == '__main__':
    # This block will only run if you have already created the .pkl files
    # from a training script.
    try:
        recommender_system = Recommender()
        if recommender_system.product_names:
            waste = "a few old glass jars with lids"
            recommendations = recommender_system.recommend(waste)
            print(f"Waste Item: '{waste}'")
            print(f"Top Recommendations: {recommendations}")
    except Exception as e:
        print(e)